{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText Example\n",
    "This notebook contains an example of loading pre-existing FastText word embedding models and using them.\n",
    "\n",
    "In this example, we will load the FastText word embeddings that are freely available at https://fasttext.cc/docs/en/english-vectors.html, more precisely, the English aligned word embeddings from https://fasttext.cc/docs/en/aligned-vectors.html.\n",
    "\n",
    "We will go through a couple examples of how to load the word embeddings.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Installed `gensim` and `numpy` library (are included in the project's `environment.yml`)\n",
    "- Downloaded FastText model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the location of the fasttext model\n",
    "embeddings = KeyedVectors.load_word2vec_format('./models/wiki.en.align.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the embedding of a single word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'virus'\n",
    "word_embedding = embeddings[token] if token in embeddings.vocab.keys() else None\n",
    "word_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"the\", \"a\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define The Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Tokenizes the provided text\n",
    "    Args:\n",
    "        text (str): The text to be tokenized\n",
    "    Returns:\n",
    "        list(tuple(str, int)): A list of (token, count) pairs from the text without the stopwords.\n",
    "    \"\"\"\n",
    "\n",
    "    # make everything lowercase and strip punctuation\n",
    "    CUSTOM_FILTERS = [lambda x: x.lower(), strip_punctuation]\n",
    "    tokens = preprocess_string(text, CUSTOM_FILTERS)\n",
    "\n",
    "    # filter out all stopwords\n",
    "    filtered_tokens = [w for w in tokens if not w in stopwords]\n",
    "\n",
    "    # return the filtered tokens\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Text Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embedding(text):\n",
    "    \"\"\"Create the text embedding\n",
    "    Args:\n",
    "        text (str): The text to be embedded\n",
    "    Returns:\n",
    "        list(float): The array of values representing the text embedding\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare the embedding placeholder\n",
    "    embedding = np.zeros(embeddings.vector_size, dtype=np.float32)\n",
    "\n",
    "    if text is None:\n",
    "        # return the default embedding in a vanilla python object\n",
    "        return embedding\n",
    "\n",
    "    # get the text terms with frequencies\n",
    "    tokens = tokenize(text)\n",
    "    # iterate through the terms and count the number of terms\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        # sum all token embeddings of the vector\n",
    "        if token in embeddings.vocab.keys():\n",
    "            embedding += embeddings[token]\n",
    "            count += 1\n",
    "\n",
    "    if count == 0:\n",
    "        # return the empty embedding list\n",
    "        return embedding.tolist()\n",
    "\n",
    "    # average the embedding\n",
    "    embedding = embedding / count\n",
    "\n",
    "\n",
    "    # return the embedding in vanilla python object\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Today is a lovely day\"\n",
    "text_embedding(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
